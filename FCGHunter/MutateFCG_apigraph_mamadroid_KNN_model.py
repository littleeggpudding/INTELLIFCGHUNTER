import sys
import os
import pygmo as pg
import tensorflow as tf
import torch
import argparse
import random
import copy
import psutil
import glob
import pickle


sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
from type.FCG_apigraph import FCG_apigraph
from type.FCG_mamadroid import FCG_mamadroid
import numpy as np
from utils import load_model, load_MLP_model
from utils import save_graph_for_every_generation, save_log_for_every_generation, save_log_for_every_individual
from utils import _init_population_our as _init_population
from utils import deal_with_conflict
from utils import calculate_opposite_adjustment
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("device", device)


#global variable
save_dir = None
model = None #surrogate model, GPU
sub_model = None #surrogate model
sub_model_name = None
target_model = None #target model
target_model_name = None # KNN_1 or KNN_3
feature_type = None # apigraph or mamadroid

# for calculate the fitness function: distance between benign and malware
benign_knn_model = None
malware_knn_model = None


def ga(fcg, max_generation = 100, pop_num = 100, steps = 300, sensitive = True, sub = True, group = False):
    """
        Genetic Algorithm (GA) for optimizing the function call graph (FCG) through mutation and crossover operations.
        Key steps:
        1. **Initialization**: A population of FCG mutations is created with `_init_population`.
        2. **Fitness Evaluation**: The population is scored using `_population_score` to evaluate how well each individual performs.
        3. **Selection**: The two best-performing individuals are selected using `_ga_select` for crossover and mutation.
        4. **Crossover & Mutation**: New individuals are generated by crossing over two selected parents and applying mutation steps to further evolve them.
        5. **Conflict Resolution**: Any conflicts within the mutated FCGs are resolved using `deal_with_conflict`.
        6. **Evolution**: The top-performing individuals from the current and previous generations are selected to form the next generation.
        7. **Termination**: The process repeats for `max_generation` iterations, or stops early if an optimal solution is found.
    """

    # sensitive: for control if the mutation is in sensitive area
    # sub: for control if using surrogate model
    # group: for control if using dependency-aware

    population = _init_population(fcg, pop_num, steps, sensitive, group)
    pop_label_list, pop_score_list, mlp_pop_list, pop_shap_list = _population_score(fcg, population, sub)
    indexes = np.argsort(pop_score_list)[:pop_num]
    population = [population[i] for i in indexes]
    pop_score_list = [pop_score_list[i] for i in indexes]
    mlp_pop_list = [mlp_pop_list[i] for i in indexes]
    pop_shap_list = [pop_shap_list[i] for i in indexes]
    pop_label_list = [pop_label_list[i] for i in indexes]
    if len(pop_score_list) == 0:
        return None

    #2. ga
    for i in range(max_generation):
        tf.keras.backend.clear_session()

        # 2.1 check if the target is found
        target_index = _fitness_function(pop_label_list)
        if target_index != -1:
            print("fitness function is true")
            save_log_for_every_individual(fcg, population[target_index], mlp_pop_list[target_index], i, save_dir)
            break

        next_gene_population = []

        save_log_for_every_generation(fcg, mlp_pop_list, pop_shap_list, i, population, save_dir)


        #2.2 generate next generation
        while True:
            if len(next_gene_population) >= pop_num:
                next_gene_population = next_gene_population[:pop_num]
                break

            #2.3 random select two individual, using tornament selection
            individual1_index, individual2_index = _ga_select(population, pop_score_list, mlp_pop_list, pop_shap_list, int(pop_num/2)-1)
            individual1 = population[individual1_index]
            individual2 = population[individual2_index]

            new_individual = copy.deepcopy(individual1)
            new_individual.crossover(individual2, fcg)
            cur_fcg = deal_with_conflict(fcg, new_individual, group)# don't change fcg

            #2.4 ga mutation
            new_individual.ga_mutation(cur_fcg, 0.2, sensitive)

            #2.5 update dependency
            if not group:
                new_individual.update_dependency()

            #2.6 append to next_gene_population
            next_gene_population.append(new_individual)


        cur_pop_label_list, cur_pop_score_list, cur_mlp_pop_list, cur_pop_shap_list = _population_score(fcg, next_gene_population, sub)
        if len(cur_pop_score_list) == 0:
            return None
        combined_population = population + next_gene_population
        combined_score_list = pop_score_list + cur_pop_score_list
        combined_shap_list = pop_shap_list + cur_pop_shap_list
        combined_mlp_list = mlp_pop_list + cur_mlp_pop_list
        combined_label_list = pop_label_list + cur_pop_label_list

        top_pop, top_score, top_mlp_score, top_shap, top_label = sort_all_pop(combined_population, combined_score_list,
                                                                              combined_mlp_list, combined_shap_list,
                                                                              combined_label_list, pop_num)

        population = top_pop
        pop_score_list = top_score
        pop_shap_list = top_shap
        mlp_pop_list = top_mlp_score
        pop_label_list = top_label

    return population



def _individual_score(fcg, individual):
    fcg = copy.deepcopy(fcg)

    original_combined_feature = extract_feature_use_fcg(fcg)
    if original_combined_feature is None:
        print("feature is none")
        return None

    for j in range(len(individual.final_group_list)):
        group = individual.final_group_list[j]
        safe_mutation = []
        for i in range(len(group)):
            mutation = group[i]
            state, res = fcg.process_mutation(mutation)
            if state:
                safe_mutation.append(mutation)
        individual.final_group_list[j] = safe_mutation

    # 1. features
    combined_feature = extract_feature_use_fcg(fcg)
    if combined_feature is None:
        print("new feature is none")
        return None

    return original_combined_feature, combined_feature, fcg



def extract_feature_use_fcg(fcg):
    feature = None
    if feature_type == 'mamadroid':
        feature = fcg.cal_mamadroid_feature()
    elif feature_type == 'apigraph':
        feature = fcg.cal_apigraph_feature()
    non_zero_feature = np.count_nonzero(feature)
    if non_zero_feature != 0:
        feature = feature.flatten()
        return feature
    else:
        return None


def _fitness_function(pop_score_list):
    target_index = -1
    print("pop_score_list", pop_score_list)
    for i in range(len(pop_score_list)):
        if pop_score_list[i] is not None and pop_score_list[i] == 0:
            target_index = i
            break
    return target_index


def _population_score(fcg, pop, sub=True):
    # shap + sub score + original score
    score_list = []
    shap_list = []
    MLP_score_list = []  # surrogate model score
    pop_feature_list = []
    pop_fcg_list = []
    y_label_list = []

    for i in range(len(pop) - 1, -1, -1):

        res = _individual_score(fcg, pop[i])
        # if score is None or shap_sum is None:
        if res is None:
            del pop[i]
        else:
            original_feature, combined_feature, cur_fcg = res

            shap_sum = calculate_opposite_adjustment(original_feature, combined_feature, fcg.shap_value)
            combined_feature = combined_feature.reshape(1, -1)
            pop_feature_list.extend(combined_feature)
            pop_fcg_list.append(cur_fcg)

            shap_list.append(shap_sum)

    pop_feature_list = np.array(pop_feature_list)
    if sub:
        all_mlp_scores = sub_model.predict(pop_feature_list)
    else:
        all_mlp_scores = len(pop) * [[0]]

    all_benign_distance, all_benign_indices = benign_knn_model.kneighbors(pop_feature_list)
    all_malware_distance, all_malware_indices = malware_knn_model.kneighbors(pop_feature_list)

    all_Y_pred = target_model.predict(pop_feature_list)

    for i in range(len(pop)):
        benign_distance = 0
        malware_distance = 0
        if target_model_name == 'KNN_1':
            # top1 benign distance
            benign_distance = all_benign_distance[i][0]
            # top1 malware distance
            malware_distance = all_malware_distance[i][0]
        elif target_model_name == 'KNN_3':
            # top2 benign distance
            benign_distance = (all_benign_distance[i][0] + all_benign_distance[i][1]) / 2.0
            # top2 malware distance
            malware_distance = (all_malware_distance[i][0] + all_malware_distance[i][1]) / 2.0

        # distance, smaller is better
        score = benign_distance - malware_distance
        score_list.append(score)
        # MLP score
        MLP_score_list.append(all_mlp_scores[i][0])

        cur_fcg = pop_fcg_list[i]

        # y_label
        cur_label = all_Y_pred[i]
        y_label_list.append(cur_label)

        if cur_label == 0:
            save_graph_for_every_generation(cur_fcg, 'success', -1, save_dir)

    return y_label_list[::-1], score_list[::-1], MLP_score_list[::-1], shap_list[::-1]


def select(pop_score_list, pop_mlp_list, pop_shap_list, idxes=None):

    # dominate version
    pop_mlp_candidate = [pop_mlp_list[idx] for idx in idxes]
    pop_score_candidate = [pop_score_list[idx] for idx in idxes]
    pop_shap_candidate = [pop_shap_list[idx] for idx in idxes]

    if len(idxes) == 1:
        return idxes[0]

    # For the score, the smaller the better; for the shap, the larger the better
    com = []
    for i in range(len(pop_score_candidate)):
        score = pop_score_candidate[i]
        mlp = pop_mlp_candidate[i]
        shap = -pop_shap_candidate[i]
        com.append([score, shap, mlp])

    ndf, dl, dc, ndr = pg.fast_non_dominated_sorting(points=com)

    return idxes[ndf[0][0]]


def sort_all_pop(pop, pop_score_list, pop_mlp_list, pop_shap_list, pop_label_list, pop_number):
    #dominate version
    com = []
    for i in range(len(pop_score_list)):
        mlp = pop_mlp_list[i]
        score = pop_score_list[i]
        shap = -pop_shap_list[i]
        com.append([score, mlp, shap])

    # print("com", com)
    ndf, dl, dc, ndr = pg.fast_non_dominated_sorting(points=com)
    # print("ndf", ndf)
    pop_total = []
    pop_score_list_total = []
    pop_shap_list_total = []
    pop_mlp_list_total = []
    pop_label_list_total = []
    for level in ndf:
        for idx in level:
            # print("idx", idx)
            pop_total.append(pop[idx])
            pop_score_list_total.append(pop_score_list[idx])
            pop_shap_list_total.append(pop_shap_list[idx])
            pop_mlp_list_total.append(pop_mlp_list[idx])
            pop_label_list_total.append(pop_label_list[idx])
            if len(pop_total) >= pop_number:
                break

        if len(pop_total) >= pop_number:
            break

    return pop_total, pop_score_list_total, pop_mlp_list_total, pop_shap_list_total, pop_label_list_total

def _ga_select(pop, pop_score_list, pop_mlp_list, pop_shap_list, tournament_size=20):
    tournament_size = min(tournament_size, len(pop))

    # Select two individuals' indices
    winner_indices = set()
    while True:
        tournament_indices = random.sample(range(len(pop)), tournament_size)
        winner_index = select(pop_score_list, pop_mlp_list, pop_shap_list, tournament_indices)
        winner_indices.add(winner_index)
        if len(winner_indices) >= 2:
            break

    winner_indices = list(winner_indices)

    return winner_indices[0], winner_indices[1]


def parse_arguments():
    """
    Function to initialize the argument parser and parse command-line arguments.

    Returns:
    --------
    args : argparse.Namespace
        Parsed arguments from the command line.
    """
    # Initialize the argument parser
    parser = argparse.ArgumentParser(description="Process some input paths and settings.")

    # Define arguments
    parser.add_argument('--save_path', type=str, required=True, help="Directory to save the results.")
    parser.add_argument('--attack_sample', type=str, required=True, help="Path to the attack samples.")
    parser.add_argument('--target_model', type=str, required=True, help="Path to the target model.")
    parser.add_argument('--target_model_name', type=str, required=True, help="Name of to the target model.")
    parser.add_argument('--surrogate_model', type=str, help="Path to the surrogate model.")
    parser.add_argument('--surrogate_model_name', type=str, choices=['MLP'],
                        help="Name of the surrogate model (must be MLP).")
    parser.add_argument('--shap_value', type=str, help="Path to the shap value file (optional).")
    parser.add_argument('--benign_KNN_model', type=str, required=True, help="Path to the knn model for retrieving the top N nearest benign sample.")
    parser.add_argument('--malware_KNN_model', type=str, required=True,
                        help="Path to the knn model for retrieving the top N nearest malware sample.")
    parser.add_argument('--feature_type', type=str, required=True, choices=['apigraph', 'mamadroid'],
                        help="Type of feature extraction method (mamadroid or apigraph).")


    # basic parameters
    parser.add_argument('--pop_num', type=int, required=True, help="Number of population during GA.")
    parser.add_argument('--max_generation', type=int, required=True, help="Number of max generations.")
    parser.add_argument('--steps', type=int, required=True, help="Number of mutation steps.")


    # optional parameters for ablation study
    parser.add_argument('--non-sensitive', action='store_true', help="Disable sensitive area.")
    parser.add_argument('--non-dependency', action='store_true', help="Disable dependency-aware.")
    parser.add_argument('--non-surrogate', action='store_true', help="Disable surrogate model.")
    parser.add_argument('--non-shap', action='store_true', help="Disable shap value.")

    return parser.parse_args()



if __name__ == '__main__':
    # Systematically set the CPU affinity for the current process
    p = psutil.Process(os.getpid())
    p.cpu_affinity(list(range(1, 110)))

    # For running the script in parallel
    if len(sys.argv) > 2:
        try:
            proc_id = int(sys.argv[1])
            proc_total = int(sys.argv[2])
            print(f"Received part index: {proc_id}")
        except ValueError:
            proc_id = 0
            proc_total = 1
            print("Error: The first argument must be an integer.")
    else:
        proc_id = 0
        proc_total = 1

    # 1.Initialize the parameters
    args = parse_arguments()

    # 2. Read attack samples from txt file
    attack_samples = glob.glob(args.attack_sample)
    print("attack_samples", len(attack_samples))

    part_size = len(attack_samples) // proc_total
    extra = len(attack_samples) % proc_total
    start_index = proc_id * part_size + min(proc_id, extra)
    if proc_id < extra:
        part_size += 1
    end_index = start_index + part_size

    # 3. Load the target model
    target_model = load_model(args.target_model)
    target_model_name = args.target_model_name

    # 4. Load the surrogate model
    sub = True  # default is using surrogate model
    if args.non_surrogate is False:
        sub_model = load_MLP_model(args.surrogate_model)
        sub_model_name = args.surrogate_model_name
    else:
        sub = False

    # 5. Load the KNN model
    benign_knn_model = load_model(args.benign_KNN_model)
    malware_knn_model = load_model(args.malware_KNN_model)

    # 5. Load the shap value
    shap_values = None  # including all attack samples, list type
    feature_type = args.feature_type
    if args.non_shap is False:
        with open(args.shap_value, 'rb') as file:
            shap_values = pickle.load(file)
        shap_values = shap_values[0]  # only using the benign's shap value
    else:
        if feature_type == 'apigraph':
            shap_values = [0] * 2704 # vector of apigraph is 2704
        else:
            shap_values = [0] * 121 # vector of mamadroid is 121

    sensitive = True  # default is using sensitive area
    if args.non_sensitive:
        sensitive = False

    group = False  # default is using dependency-aware
    if args.non_dependency:
        group = True


    for i in range(start_index, end_index):
        fcg_file = attack_samples[i]
        fcg = None
        feature = None
        if feature_type == 'mamadroid':
            fcg = FCG_mamadroid(fcg_file, 1, shap_values)
            feature = fcg.cal_mamadroid_feature()
        elif feature_type == 'apigraph':
            fcg = FCG_apigraph(fcg_file, 1, shap_values)
            feature = fcg.cal_apigraph_feature()

        non_zero_feature = np.count_nonzero(feature)
        if non_zero_feature != 0:
            feature = feature.flatten()
            new_feature = feature.reshape(1, -1)

            Y_probs = target_model.predict(new_feature)
            print("Y_probs", Y_probs)

            if Y_probs[0] == 0:
                print("benign")

            else:
                print("malware")
                save_dir = args.save_path
                if not os.path.exists(save_dir):
                    os.makedirs(save_dir)

                generation = args.max_generation
                pop_num = args.pop_num
                steps = args.steps
                
                ga(fcg, generation, pop_num, steps, sensitive, sub, group)
                





